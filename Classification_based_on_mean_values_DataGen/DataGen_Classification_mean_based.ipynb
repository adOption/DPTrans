{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import wntr\n",
    "import networkx as nx\n",
    "import copy\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datafiles required for training and testing the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting path for the 'parent folder'\n",
    "path_cwd = os.getcwd()\n",
    "path_parent = os.path.abspath(os.path.join(path_cwd, os.pardir))\n",
    "\n",
    "# Getting path for the data files\n",
    "datafiles_folder_name = 'Data_files'\n",
    "\n",
    "file_train = 'data_base_demand_train_1.csv'\n",
    "file_test_base_demand = 'data_base_demand_test.csv'\n",
    "file_test_diff_demand_low = 'data_diff_demand_low.csv'\n",
    "file_test_diff_demand_high = 'data_diff_demand_high.csv'\n",
    "\n",
    "file_leak14 = 'data_leak_in_14.csv'\n",
    "file_leak24 = 'data_leak_in_24.csv'\n",
    "file_leak31 = 'data_leak_in_31.csv'\n",
    "\n",
    "path_train = os.path.join(path_parent,datafiles_folder_name,file_train)\n",
    "path_test_base_demand = os.path.join(path_parent,datafiles_folder_name,file_test_base_demand)\n",
    "path_test_diff_demand_low = os.path.join(path_parent,datafiles_folder_name,file_test_diff_demand_low)\n",
    "path_test_diff_demand_high = os.path.join(path_parent,datafiles_folder_name,file_test_diff_demand_high)\n",
    "path_leak14 = os.path.join(path_parent,datafiles_folder_name,file_leak14)\n",
    "path_leak24 = os.path.join(path_parent,datafiles_folder_name,file_leak24)\n",
    "path_leak31 = os.path.join(path_parent,datafiles_folder_name,file_leak31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy for historical observations\n",
    "data_train_df = pd.read_csv(path_train)\n",
    "\n",
    "# Proxy for recent observations, those need to be tested for leak\n",
    "data_test_df = pd.read_csv(path_test_base_demand)\n",
    "leak_file_14 = pd.read_csv(path_leak14)\n",
    "leak_file_24 = pd.read_csv(path_leak24)\n",
    "leak_file_31 = pd.read_csv(path_leak31)\n",
    "data_test_df_diff_demand_low = pd.read_csv(path_test_diff_demand_low)\n",
    "data_test_df_diff_demand_high = pd.read_csv(path_test_diff_demand_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature names that will be used to while creating train and test data for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_list = [[4,4],[9,8],[18,17],[20,20],[26,27],[28,30],[32,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_noleak = ['Node_head'+str(i) for i in [4,9,18,20,26,28,32]]+['Link_flow'+str(i) for i in [4,8,17,20,27,30,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_leak = ['leak_head_'+str(i) for i in [4,9,18,20,26,28,32]]+['leak_flow_'+str(i) for i in [4,8,17,20,27,30,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_means_ref = ['ref_mean_head'+str(i) for i in [4,9,18,20,26,28,32]]+['ref_mean_flow'+str(i) for i in [4,8,17,20,27,30,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_means = ['mean_head'+str(i) for i in [4,9,18,20,26,28,32]]+['mean_flow'+str(i) for i in [4,8,17,20,27,30,33]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing leak data into train and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_data_14 = leak_file_14.loc[leak_file_14.leak_area.isin([0.0005,0.002,0.003,0.004])]\n",
    "leak_data_24 = leak_file_24.loc[leak_file_24.leak_area.isin([0.0005,0.002,0.003,0.004])]\n",
    "leak_data_31 = leak_file_31.loc[leak_file_31.leak_area.isin([0.0005,0.002,0.003,0.004])]\n",
    "\n",
    "leak_data_14_test = leak_file_14.loc[leak_file_14.leak_area.isin([0.0001,0.001,0.005])]\n",
    "leak_data_24_test = leak_file_24.loc[leak_file_24.leak_area.isin([0.0001,0.001,0.005])]\n",
    "leak_data_31_test = leak_file_31.loc[leak_file_31.leak_area.isin([0.0001,0.001,0.005])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 168) (153, 168)\n"
     ]
    }
   ],
   "source": [
    "print(leak_data_14.shape,leak_data_14_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining length of the random samples that would be selected from above mentioned datasets and their means would be stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 5\n",
    "trainfrac = sample_length/len(data_train_df)\n",
    "testfrac = sample_length/len(data_test_df)\n",
    "testfrac_diff_low = sample_length/len(data_test_df_diff_demand_low)\n",
    "testfrac_diff_high = sample_length/len(data_test_df_diff_demand_high)\n",
    "leakfrac = sample_length/len(leak_data_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10416666666666667 0.09615384615384616 0.21739130434782608 0.23809523809523808 0.024509803921568627\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(trainfrac,testfrac,testfrac_diff_low,testfrac_diff_high,leakfrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining size of training set. Prefer choosing a multiple of 6 \n",
    "num_training_sample_total = 180\n",
    "num_training_sample_leak = int(num_training_sample_total/6)\n",
    "num_training_sample_noleak = num_training_sample_total - 3* (num_training_sample_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 90\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(num_training_sample_leak,num_training_sample_noleak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data with and without leak\n",
    "* We have assumed 7 sensor locations, each measuring flowrate and pressure\n",
    "* First 7 pressure head + 7 flowrate columns that represent mean values of the  'expected' sensor observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_reference=[]\n",
    "for i in range (num_training_sample_total):\n",
    "    mean_train_reference.append(list(data_train_df[cols_noleak].sample(frac=trainfrac).mean()))\n",
    "mean_train_df_ref = pd.DataFrame(columns=cols_means_ref,data=np.array(mean_train_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next 7 pressure and 7 flowrate columns that represent 'observed' means that are known to belong to a leak or 'no leak' case\n",
    "* 2 set of labels are added, first one in named 'leak' and is binary. Other is named 'num_leak' and has four values i.e. 0,14,24 and 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train=[]\n",
    "for i in range (num_training_sample_noleak):\n",
    "    mean_train.append(list(data_train_df[cols_noleak].sample(frac=trainfrac).mean()))\n",
    "    \n",
    "mean_train_df = pd.DataFrame(columns=cols_means,data=np.array(mean_train))\n",
    "mean_train_df['leak']=0\n",
    "mean_train_df['num_leak']=0\n",
    "\n",
    "mean_leak=[]\n",
    "leaknum=[]\n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak.append(list(leak_data_14[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum.append(14)\n",
    "    \n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak.append(list(leak_data_24[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum.append(24)\n",
    "    \n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak.append(list(leak_data_31[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum.append(31)\n",
    "    \n",
    "mean_leak_df = pd.DataFrame(columns=cols_means,data=np.array(mean_leak))\n",
    "mean_leak_df['leak']=1\n",
    "mean_leak_df['num_leak']=leaknum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combining the leak and no leak data together to form 'training set' for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = mean_train_df.append(mean_leak_df,ignore_index=True)\n",
    "training_classification = pd.concat([mean_train_df_ref,df_temp1],axis=1)\n",
    "training_classification = training_classification.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_mean_head4</th>\n",
       "      <th>ref_mean_head9</th>\n",
       "      <th>ref_mean_head18</th>\n",
       "      <th>ref_mean_head20</th>\n",
       "      <th>ref_mean_head26</th>\n",
       "      <th>ref_mean_head28</th>\n",
       "      <th>ref_mean_head32</th>\n",
       "      <th>ref_mean_flow4</th>\n",
       "      <th>ref_mean_flow8</th>\n",
       "      <th>ref_mean_flow17</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_head32</th>\n",
       "      <th>mean_flow4</th>\n",
       "      <th>mean_flow8</th>\n",
       "      <th>mean_flow17</th>\n",
       "      <th>mean_flow20</th>\n",
       "      <th>mean_flow27</th>\n",
       "      <th>mean_flow30</th>\n",
       "      <th>mean_flow33</th>\n",
       "      <th>leak</th>\n",
       "      <th>num_leak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>140.322642</td>\n",
       "      <td>120.588803</td>\n",
       "      <td>132.632025</td>\n",
       "      <td>131.868700</td>\n",
       "      <td>108.880792</td>\n",
       "      <td>108.608765</td>\n",
       "      <td>107.066691</td>\n",
       "      <td>2.401865</td>\n",
       "      <td>1.278237</td>\n",
       "      <td>-0.438791</td>\n",
       "      <td>...</td>\n",
       "      <td>147.474237</td>\n",
       "      <td>2.292302</td>\n",
       "      <td>1.220457</td>\n",
       "      <td>-0.428846</td>\n",
       "      <td>2.373272</td>\n",
       "      <td>-0.075435</td>\n",
       "      <td>0.165640</td>\n",
       "      <td>0.179139</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>157.148621</td>\n",
       "      <td>137.286484</td>\n",
       "      <td>150.284364</td>\n",
       "      <td>148.406133</td>\n",
       "      <td>123.677857</td>\n",
       "      <td>124.120527</td>\n",
       "      <td>121.212152</td>\n",
       "      <td>2.388643</td>\n",
       "      <td>1.295577</td>\n",
       "      <td>-0.429482</td>\n",
       "      <td>...</td>\n",
       "      <td>90.428589</td>\n",
       "      <td>2.419493</td>\n",
       "      <td>1.316568</td>\n",
       "      <td>-0.429192</td>\n",
       "      <td>2.503072</td>\n",
       "      <td>-0.060320</td>\n",
       "      <td>0.158231</td>\n",
       "      <td>0.147877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>188.814297</td>\n",
       "      <td>167.048915</td>\n",
       "      <td>182.006465</td>\n",
       "      <td>179.037187</td>\n",
       "      <td>152.447853</td>\n",
       "      <td>154.376955</td>\n",
       "      <td>149.482185</td>\n",
       "      <td>2.520204</td>\n",
       "      <td>1.363075</td>\n",
       "      <td>-0.438384</td>\n",
       "      <td>...</td>\n",
       "      <td>137.222150</td>\n",
       "      <td>2.224304</td>\n",
       "      <td>1.175552</td>\n",
       "      <td>-0.391558</td>\n",
       "      <td>2.301164</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>0.134292</td>\n",
       "      <td>0.123306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ref_mean_head4  ref_mean_head9  ref_mean_head18  ref_mean_head20  \\\n",
       "166      140.322642      120.588803       132.632025       131.868700   \n",
       "29       157.148621      137.286484       150.284364       148.406133   \n",
       "33       188.814297      167.048915       182.006465       179.037187   \n",
       "\n",
       "     ref_mean_head26  ref_mean_head28  ref_mean_head32  ref_mean_flow4  \\\n",
       "166       108.880792       108.608765       107.066691        2.401865   \n",
       "29        123.677857       124.120527       121.212152        2.388643   \n",
       "33        152.447853       154.376955       149.482185        2.520204   \n",
       "\n",
       "     ref_mean_flow8  ref_mean_flow17  ...  mean_head32  mean_flow4  \\\n",
       "166        1.278237        -0.438791  ...   147.474237    2.292302   \n",
       "29         1.295577        -0.429482  ...    90.428589    2.419493   \n",
       "33         1.363075        -0.438384  ...   137.222150    2.224304   \n",
       "\n",
       "     mean_flow8  mean_flow17  mean_flow20  mean_flow27  mean_flow30  \\\n",
       "166    1.220457    -0.428846     2.373272    -0.075435     0.165640   \n",
       "29     1.316568    -0.429192     2.503072    -0.060320     0.158231   \n",
       "33     1.175552    -0.391558     2.301164    -0.056522     0.134292   \n",
       "\n",
       "     mean_flow33  leak  num_leak  \n",
       "166     0.179139     1        31  \n",
       "29      0.147877     0         0  \n",
       "33      0.123306     0         0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "training_classification.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data without leak (same and diff demand) and with leak (same demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First 7 pressure and 7 flowrate features representing 'expected' sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_reference=[]\n",
    "for i in range (num_training_sample_total):\n",
    "    mean_test_reference.append(list(data_train_df[cols_noleak].sample(frac=trainfrac).mean()))\n",
    "\n",
    "mean_test_df_ref = pd.DataFrame(columns=cols_means_ref,data=np.array(mean_test_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next 7 plus 7 features representing the 'recently observed' or 'to be tested for leak' observations or sensor readings across 7 sensor locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_same_demand=[]\n",
    "for i in range (num_training_sample_noleak):\n",
    "    mean_test_same_demand.append(list(data_test_df[cols_noleak].sample(frac=testfrac).mean()))\n",
    "    \n",
    "mean_test_df_same_demand = pd.DataFrame(columns=cols_means,data=np.array(mean_test_same_demand)) \n",
    "mean_test_df_same_demand['leak']=0\n",
    "mean_test_df_same_demand['num_leak']=0\n",
    "\n",
    "\n",
    "mean_test_diff_demand_low=[]\n",
    "for i in range (num_training_sample_noleak):\n",
    "    mean_test_diff_demand_low.append(list(data_test_df_diff_demand_low[cols_noleak].sample(frac=testfrac_diff_low).mean()))\n",
    "    \n",
    "mean_test_df_diff_demand_low = pd.DataFrame(columns=cols_means,data=np.array(mean_test_diff_demand_low)) \n",
    "mean_test_df_diff_demand_low['leak']=0\n",
    "mean_test_df_diff_demand_low['num_leak']=0\n",
    "\n",
    "mean_test_diff_demand_high=[]\n",
    "for i in range (num_training_sample_noleak):\n",
    "    mean_test_diff_demand_high.append(list(data_test_df_diff_demand_high[cols_noleak].sample(frac=testfrac_diff_high).mean()))\n",
    "    \n",
    "mean_test_df_diff_demand_high = pd.DataFrame(columns=cols_means,data=np.array(mean_test_diff_demand_high)) \n",
    "mean_test_df_diff_demand_high['leak']=0\n",
    "mean_test_df_diff_demand_high['num_leak']=0\n",
    "\n",
    "\n",
    "mean_leak_same_demand=[]\n",
    "leaknum_test_same=[]\n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak_same_demand.append(list(leak_data_14_test[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum_test_same.append(14)\n",
    "    \n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak_same_demand.append(list(leak_data_24_test[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum_test_same.append(24)\n",
    "    \n",
    "for i in range (num_training_sample_leak):\n",
    "    mean_leak_same_demand.append(list(leak_data_31_test[cols_leak].sample(frac=leakfrac).mean()))\n",
    "    leaknum_test_same.append(31)\n",
    "    \n",
    "mean_leak_df_same_demand = pd.DataFrame(columns=cols_means,data=np.array(mean_leak_same_demand))\n",
    "mean_leak_df_same_demand['leak']=1\n",
    "mean_leak_df_same_demand['num_leak']=leaknum_test_same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only original demand based test sets, with both 'no leak' and 'with leak' scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1=mean_test_df_same_demand.append(mean_leak_df_same_demand,ignore_index=True)\n",
    "test_classification_1=pd.concat([mean_test_df_ref,df_temp1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set combining the 'no leak' cases from different demand based scenarios AND leak cases based on 'original' demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2=mean_test_df_diff_demand_low.append(mean_leak_df_same_demand,ignore_index=True)\n",
    "test_classification_2=pd.concat([mean_test_df_ref,df_temp2],axis=1)\n",
    "\n",
    "df_temp3=mean_test_df_diff_demand_high.append(mean_leak_df_same_demand,ignore_index=True)\n",
    "test_classification_3=pd.concat([mean_test_df_ref,df_temp3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification_1=test_classification_1.sample(frac=1)\n",
    "test_classification_2=test_classification_2.sample(frac=1)\n",
    "test_classification_3=test_classification_3.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 30)\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(test_classification_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folder name defined\n",
    "datafiles_folder_name = 'Data_files'\n",
    "\n",
    "# Output file names defined\n",
    "datafile_training = 'data_training_classification_mean_based.csv'\n",
    "datafile_test1 = 'data_testing_classification_mean_based_BaseDemand.csv'\n",
    "datafile_test2 = 'data_testing_classification_mean_based_DiffLow.csv'\n",
    "datafile_test3 = 'data_testing_classification_mean_based_DiffHigh.csv'\n",
    "\n",
    "# Creating file paths. Note that 'path_parent' has been defined earlier\n",
    "path_training = os.path.join(path_parent,datafiles_folder_name,datafile_training)\n",
    "path_test1 = os.path.join(path_parent,datafiles_folder_name,datafile_test1)\n",
    "path_test2 = os.path.join(path_parent,datafiles_folder_name,datafile_test2)\n",
    "path_test3 = os.path.join(path_parent,datafiles_folder_name,datafile_test3)\n",
    "\n",
    "# Creating the 'Data_files' folder if it doesn't exist\n",
    "os.makedirs(os.path.dirname(path_training), exist_ok=True)\n",
    "\n",
    "# Saving the output datasets as csv files whose paths have been defined above\n",
    "training_classification.to_csv(path_training, index=None)\n",
    "test_classification_1.to_csv(path_test1, index=None)\n",
    "test_classification_2.to_csv(path_test2, index=None)\n",
    "test_classification_3.to_csv(path_test3, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
